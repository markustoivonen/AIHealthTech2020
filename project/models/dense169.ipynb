{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dense169.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMV2EnvQU8rCegvb11tkNqs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markustoivonen/AIHealthTech2020/blob/master/project/models/dense169.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzy_6wTX43c7",
        "outputId": "3cff099a-717f-4414-d100-b3266b121210"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import glob\n",
        "from subprocess import getoutput\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import (ModelCheckpoint, TensorBoard)\n",
        "from keras.applications.densenet import preprocess_input\n",
        "from keras.models import load_model\n",
        "import warnings\n",
        "from keras.layers import Dense, Flatten\n",
        "import keras\n",
        "warnings.filterwarnings('ignore')  # Ignore python warnings\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3Z5yVgB5Cct"
      },
      "source": [
        "## Define the Dense169 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN1Zw27_5Oqq"
      },
      "source": [
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "def get_dense169(input_shape, learning_rate):\n",
        "    # create the base pre-trained model\n",
        "    dense_169_model = DenseNet169(include_top=False, weights='imagenet', input_shape=(input_shape, input_shape, 3))\n",
        "    x = dense_169_model.output\n",
        "    model = keras.Sequential([dense_169_model, Flatten(), Dense(1, activation='sigmoid')])\n",
        "\n",
        "    for layer in dense_169_model.layers:\n",
        "        layer.trainable = True\n",
        "    adam = optimizers.Adam(lr=learning_rate)\n",
        "    model.compile(optimizer=adam,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enManzyI5V_T"
      },
      "source": [
        "### Define hyperparams & create architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbYBSuuB5aWx",
        "outputId": "00cce4ea-c342-4ab8-f779-08ebf4d18f03"
      },
      "source": [
        "input_shape = 320\n",
        "batch_size = 8\n",
        "epochs = 10\n",
        "learning_rate = 0.0001\n",
        "\n",
        "dense169_mura_single = get_dense169(input_shape, learning_rate)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "51879936/51877672 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Waj-n_v5zqz"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuLOB7nr5myD"
      },
      "source": [
        "#### Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyeoNkmI5oV4",
        "outputId": "c2a85700-7ff6-4a85-d902-504bd4d2dde2"
      },
      "source": [
        "# If you want to reduce the size of the training dataset,\n",
        "# set validation_split=0.95 or greater\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=30,\n",
        "        horizontal_flip=True,\n",
        "        preprocessing_function=preprocess_input,\n",
        "        validation_split=0)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/MURA-v1.2/train_data/',\n",
        "        target_size=(input_shape, input_shape),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',\n",
        "        subset='training')\n",
        "training_data_size = len(train_generator.filenames)\n",
        "print(\"Number of Training examples: \", training_data_size)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 37 images belonging to 2 classes.\n",
            "Number of Training examples:  37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54Di7jrX5oia"
      },
      "source": [
        "#### Validation data and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-qo4DmX5rfw",
        "outputId": "da25b396-8ef8-4d1e-e9da-b3620919345e"
      },
      "source": [
        "# Set seed so we do not have overlap in validation and in test set\n",
        "seed = 1025\n",
        "\n",
        "# Set validation split accordingly, 0.3 makes the sizes to be about 2k / 1k (valid/test)\n",
        "valid_and_test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.99)\n",
        "\n",
        "valid_generator = valid_and_test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/MURA-v1.2/valid_data',\n",
        "        target_size=(input_shape, input_shape),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',\n",
        "        shuffle=False,\n",
        "        subset=\"training\",\n",
        "        seed=seed)\n",
        "\n",
        "\n",
        "test_generator = valid_and_test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/MURA-v1.2/valid_data',\n",
        "    target_size=(input_shape, input_shape),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False,\n",
        "    subset=\"validation\",\n",
        "    seed=seed\n",
        ")\n",
        "validation_data_size = len(valid_generator.filenames)\n",
        "print(\"Number of Validation examples: \", validation_data_size)\n",
        "test_data_size = len(test_generator.filenames)\n",
        "print(\"Number of Test examples: \", test_data_size)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 33 images belonging to 2 classes.\n",
            "Found 3164 images belonging to 2 classes.\n",
            "Number of Validation examples:  33\n",
            "Number of Test examples:  3164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtuHRZq179xM"
      },
      "source": [
        "### Class weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPXKGrSM793B",
        "outputId": "6fe318c0-8057-45a2-e85e-ea775fcac079"
      },
      "source": [
        "weights = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)\n",
        "\n",
        "# If the training set is only of 1 class, the weights will be wrong\n",
        "# This could happen if we use a too small dataset for tinkering purposes\n",
        "if len(weights) = 1:\n",
        "  weights = [1, 1]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.23825503 0.83863636]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzHN4CVn8srs"
      },
      "source": [
        "### Saving models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjX8tEWG8szb"
      },
      "source": [
        "# make sure that a folders 'models' and 'dense169' exist in your Google Drive\n",
        "base_filepath = \"/content/drive/MyDrive/MURA-v1.2/models/dense169\"\n",
        "filepath= base_filepath+\"/dense169-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UZW99zg891F"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "Note: SKIP THIS CELL IF YOU HAVE A TRAINED MODEL ALREADY!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KF-QJyD897f",
        "outputId": "b55be148-e61b-42db-ee96-6cfd5bd2d581"
      },
      "source": [
        "dense169_mura_single.fit(train_generator,\n",
        "                        validation_data=valid_generator,\n",
        "                        steps_per_epoch=training_data_size // batch_size,\n",
        "                        class_weight={0:weights[0], 1:weights[1]},\n",
        "                        callbacks=checkpoint, \n",
        "                        validation_steps=validation_data_size // batch_size,\n",
        "                        epochs=epochs)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.7495 - accuracy: 0.7241\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.62500, saving model to /content/drive/MyDrive/MURA-v1.2/models/dense169/dense169-improvement-01-0.62.hdf5\n",
            "4/4 [==============================] - 50s 13s/step - loss: 0.7495 - accuracy: 0.7241 - val_loss: 1.0659 - val_accuracy: 0.6250\n",
            "Epoch 2/2\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8621\n",
            "Epoch 00002: val_accuracy did not improve from 0.62500\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.3845 - accuracy: 0.8621 - val_loss: 1.8777 - val_accuracy: 0.5312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f790e488da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm-crdCnDxsi"
      },
      "source": [
        "### Evaluate model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-T9_0-VD1yc"
      },
      "source": [
        "#### Load the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0cx8WWV9QyI",
        "outputId": "45e22f2b-f3f2-4083-abc7-0c5b7ca515b5"
      },
      "source": [
        "def get_latest_model(path):\n",
        "    \"\"\"Gets the latest model created. This assumes that the latest is the best one.\"\"\"\n",
        "    files = os.listdir(path)\n",
        "    paths = [os.path.join(path, basename) for basename in files]\n",
        "    return max(paths, key=os.path.getctime)\n",
        "print(\"Loading model\")\n",
        "model_fp = get_latest_model(base_filepath)\n",
        "model = load_model(model_fp)\n",
        "print(\"Model loaded\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model\n",
            "Model loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lljkCka3GfZj"
      },
      "source": [
        "#### Generate preditcions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Sy1ylUEkFb",
        "outputId": "36834b8c-e0f1-447a-b9ec-b6eac4c79dbd"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "predictions = model.predict(test_generator)\n",
        "end = time.time()\n",
        "print(\"It took: \", end - start, \"seconds to create predictions for the test set.\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It took:  1020.4360239505768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSB0ghDvXmSg"
      },
      "source": [
        "ELBOW_STUDY = \"ELBOW\"\n",
        "FINGER_STUDY = \"FINGER\"\n",
        "FOREARM_STUDY = \"FOREARM\"\n",
        "HAND_STUDY = \"HAND\"\n",
        "HUMERUS_STUDY = \"HUMERUS\"\n",
        "SHOULDER_STUDY = \"SHOULDER\"\n",
        "WRIST_STUDY = \"WRIST\"\n",
        "\n",
        "elbow_pred = []\n",
        "elbow_true = []\n",
        "finger_pred = []\n",
        "finger_true = []\n",
        "forearm_pred = []\n",
        "forearm_true = []\n",
        "hand_pred = []\n",
        "hand_true = []\n",
        "humerus_pred = []\n",
        "humerus_true = []\n",
        "shoulder_pred = []\n",
        "shoulder_true = []\n",
        "wrist_pred = []\n",
        "wrist_true = []\n",
        "\n",
        "predictions = np.round(predictions.flatten())\n",
        "y_true = test_generator.classes\n",
        "filenames = test_generator.filenames\n",
        "\n",
        "for index, filename in enumerate(filenames):\n",
        "    if ELBOW_STUDY in filename:\n",
        "        elbow_pred.append(predictions[index])\n",
        "        elbow_true.append(y_true[index])\n",
        "        \n",
        "    elif FINGER_STUDY in filename:\n",
        "        finger_pred.append(predictions[index])\n",
        "        finger_true.append(y_true[index])\n",
        "        \n",
        "    elif FOREARM_STUDY in filename:\n",
        "        forearm_pred.append(predictions[index])\n",
        "        forearm_true.append(y_true[index])\n",
        "    \n",
        "    elif HAND_STUDY in filename:\n",
        "        hand_pred.append(predictions[index])\n",
        "        hand_true.append(y_true[index])\n",
        "    \n",
        "    elif HUMERUS_STUDY in filename:\n",
        "        humerus_pred.append(predictions[index])\n",
        "        humerus_true.append(y_true[index])\n",
        "            \n",
        "    elif SHOULDER_STUDY in filename:\n",
        "        shoulder_pred.append(predictions[index])\n",
        "        shoulder_true.append(y_true[index])\n",
        "    \n",
        "    elif WRIST_STUDY in filename:\n",
        "        wrist_pred.append(predictions[index])\n",
        "        wrist_true.append(y_true[index])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK6ufw_uZev_"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, confusion_matrix, cohen_kappa_score, f1_score\n",
        "\n",
        "\n",
        "def write_all_metrics(y_true, y_pred):\n",
        "    def get_sensitivity(tp, fn):\n",
        "      return tp / (tp + fn)\n",
        "\n",
        "\n",
        "    def get_specificity(tn, fp):\n",
        "        return tn / (tn + fp)\n",
        "    results = \"\"\n",
        "    results += \"roc_auc_score: \"+str(roc_auc_score(y_true, y_pred))\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "    results += \"\\nSensitivity: \"+ str(get_sensitivity(tp, fn))\n",
        "    results += \"\\nSpecificity: \" + str(get_specificity(tn, fp))\n",
        "    results += \"\\nCohen-Cappa-Score: \" + str(cohen_kappa_score(y_true, y_pred))\n",
        "    results += \"\\nF1 Score: \" +str (f1_score(y_true, y_pred))\n",
        "    return results\n",
        "\n",
        "\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtC6-l1zZWGT"
      },
      "source": [
        "results_filename = \".\".join(model_fp.split(\".\")[0:2]) + \"_results.txt\"\n",
        "\n",
        "with open(results_filename, 'w') as f:\n",
        "  f.write(\"\\n===== ELBOW ======\\n\")\n",
        "  f.write(write_all_metrics(elbow_true,elbow_pred))\n",
        "\n",
        "  f.write(\"\\n===== FINGER ======\\n\")\n",
        "  f.write(write_all_metrics(finger_true,finger_pred))\n",
        "\n",
        "  f.write(\"\\n===== FOREARM ======\\n\")\n",
        "  f.write(write_all_metrics(forearm_true,forearm_pred))\n",
        "\n",
        "  f.write(\"\\n===== HAND ======\\n\")\n",
        "  f.write(write_all_metrics(hand_true,hand_pred))\n",
        "\n",
        "  f.write(\"\\n===== HUMERUS ======\\n\")\n",
        "  f.write(write_all_metrics(humerus_true,humerus_pred))\n",
        "\n",
        "  f.write(\"\\n===== SHOULDER ======\\n\")\n",
        "  f.write(write_all_metrics(shoulder_true, shoulder_pred))\n",
        "\n",
        "  f.write(\"\\n===== WRIST ======\\n\")\n",
        "  f.write(write_all_metrics(wrist_true,wrist_pred))"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaSaXDzKZZ38"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}