{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "self_attention_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markustoivonen/AIHealthTech2020/blob/master/exercises/ex8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zyqv7dOQQGeC"
      },
      "source": [
        "## 1.1\n",
        "\n",
        "Tokenization is breaking a text chunk in smaller parts. Whether it is breaking a paragraph in to sentences, sentence into words or word in characters. \\\\\n",
        "\n",
        "Subword tokenization means breaking words into a corpus and a subword. For example the word \"faster\" becomes \"fast\", \"er\". Thus we can learn the subwords as well.\n",
        "\n",
        "\n",
        "## 1.2\n",
        "\n",
        "One-hot encoding is inefficient. A one-hot encoded vector is sparse (meaning, most indices are zero). If we have a vocabulary of 10k words, and we one-hot encode each word, we would create a vector where 99.99\\% of the elements are zero. \\\\\n",
        "\n",
        "Embedding allows us to represent the words in a more dense way. The idea is that we project the words in our vocabulary into some space, and the mapping tries to put similar words close to each other in the space. Embedding is also something we can also improve by training. These 3 things (dense representation, relationships between words, trainability) make it much more better encoding mechanic than one-hot encoding.\n",
        "\n",
        "\n",
        "## 1.3\n",
        "\n",
        "The embeddings seem to make a little sense. For example close to one another are airport, runaway, petroleum, import and export. And in another corner there seems to be a lot of names bundles together. However, considering the first three axises only explain 8.5\\% of the variance, one should not draw too many conclusions from the relationships. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HknH60A7tWN0"
      },
      "source": [
        "# Self Attention\n",
        "\n",
        "Self attention is a mechanism made popular by the paper \"Attention Is All You Need\" https://arxiv.org/abs/1706.03762. The mechanism requires three components: Queries $Q$, Keys $K$, and Values $V$. Queries and Keys are matrices with sequence_length $\\times$ element_dimension elements. An attention matrix is produced by computing $QK^T$ with dimensions sequence_length $\\times$ sequence_length. Conceptually this can be thought to measure the similarity of the vectors located at each sequence element in the queries and keys. A row-wise softmax is then taken and the matrix is multiplied with the values. This can be thought to first introduce weights which sum up to one (the softmaxed matrix) and then a weighted sum of the sequence elements is taken. Certain sequence elements can thus dominate the output and irrelevant parts are suppressed.\n",
        "\n",
        "The self attention is often made as follows:\n",
        "Let $x$ be a matrix with dimensions sequence_length $\\times$ input_dimension, where input_dimension is for example the output of a hidden layer and sequence length is the length of a time-series etc.\n",
        "\n",
        "\\begin{align}\n",
        "Q &= xw_Q\\\\\n",
        "K &= xw_K\\\\\n",
        "V &= xw_V\\\\\n",
        "SelfAttn(Q,K,V) &= Softmax_{r}(QK^T)V\n",
        "\\end{align}\n",
        "Here the $Softmax_{r}$ is the softmax taken row-wise (each element exponentiated and then normalized via the sum of the exponentiated elements).\n",
        "The weights $w_Q,w_K$ have dimensions input_dimension$\\times$element_dimension and the $w_V$ is either the same shape or the element_dimension can also be different. Often the $SelfAttn(\\cdot)$ also includes a normalizing constant inside the softmax to make the learning more stabile. For example in the paper \"Attention Is All You Need\" the self attention is given by:\n",
        "\n",
        "\\begin{equation}\n",
        "SelfAttn(Q,K,V) = Softmax_{r}(\\frac{QK^T}{\\sqrt{d_e}})V\n",
        "\\end{equation}\n",
        "Where $d_e$ is the element_dimension (their notation is slightly different).\n",
        "\n",
        "Usually the self attention is followed by fully connected layers which map the output to either classification probabilities or to the input of another attention layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_eUHB11tT1t"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from tensorflow.data import Dataset\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akDMiZ6NjwtA"
      },
      "source": [
        "data = tfds.load(name='tiny_shakespeare')\n",
        "train_examples, val_examples = tfds.as_numpy(data['train']), tfds.as_numpy(data['validation'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmW5zKm39KGY"
      },
      "source": [
        "def process_shakespeare_to_batches(ds_in,sequence_length=101):\n",
        "    # Extract the data from the dataset object:\n",
        "    ds = next(iter(ds_in))['text']\n",
        "    # Decode the bytes as utf-8 string:\n",
        "    ds = ds.decode('UTF-8')\n",
        "    # Remove linebreaks from the text unless speaker changes:\n",
        "    ds = ds.split('\\n\\n')\n",
        "    ds = [item.replace('\\n',' ') for item in ds]\n",
        "    ds = \" \\n \".join(ds)\n",
        "    # We are going to chunk the string into sequences of 500 characters:\n",
        "    ds_new = []\n",
        "    i = 0\n",
        "    while i<len(ds):\n",
        "        my_string = ds[i:i+sequence_length]\n",
        "        if len(my_string)<sequence_length:\n",
        "            break # A quick and dirty way to make it so that all elements are 500 long\n",
        "        ds_new.append(my_string)\n",
        "        i+=sequence_length\n",
        "    ds = ds_new\n",
        "    return ds\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XROcO1ej9iol",
        "outputId": "6779db93-e352-425e-ac28-82e35ef3bc26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Chunk the play into suitable components:\n",
        "sequence_length = 101\n",
        "train_dataset = process_shakespeare_to_batches(train_examples,sequence_length=sequence_length)\n",
        "val_dataset = process_shakespeare_to_batches(val_examples,sequence_length=sequence_length)\n",
        "print(\"Number of training examples: %d, and number of validation examples: %d\"%(len(train_dataset),len(val_dataset)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 10001, and number of validation examples: 556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyyQ4hOTrgBD",
        "outputId": "abff5ff2-049a-4c7f-96dc-9dfff24122b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Now we have our datasets as lists of text.\n",
        "# Next we need to do 2 things, make them into tensorflow datasets and tokenize\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='',char_level=True,split=None)\n",
        "tokenizer.fit_on_texts(train_dataset)\n",
        "vocab_size = len(list(eval(tokenizer.get_config()['index_word']).keys()))+1 # One for unknown\n",
        "print(\"Vocab size: %d\"%vocab_size)\n",
        "train_seqs = tokenizer.texts_to_sequences(train_dataset)\n",
        "val_seqs = tokenizer.texts_to_sequences(val_dataset)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9vEuKc_y1i4"
      },
      "source": [
        "# Since the keras tokenizer will concat always with space, we need to do our own backward tokenizer:\n",
        "def sequences_to_text(dataset,tokenizer):\n",
        "    index_word = eval(tokenizer.get_config()['index_word']) # I have absolutely no idea why the keras devs think its good idea to store this dict as a string as there is no other way to access this.\n",
        "    dataset_text = []\n",
        "    for batch in dataset:\n",
        "        my_sequence = []\n",
        "        for character_token in batch:\n",
        "            my_sequence.append(index_word[str(character_token)])\n",
        "        dataset_text.append(\"\".join(my_sequence))\n",
        "    return dataset_text"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTWPRQi7zTZQ",
        "outputId": "7d51547d-1f2e-4b6e-d035-d79d5378b290",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Test if we can map the words back:\n",
        "print(\"Original sequence:\")\n",
        "print(train_dataset[0])\n",
        "print('\\n')\n",
        "tr_seq_2_text = sequences_to_text(train_seqs,tokenizer)\n",
        "print(\"Tokenized and back mapped sequence:\")\n",
        "print(tr_seq_2_text[0])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sequence:\n",
            "First Citizen: Before we proceed any further, hear me speak. \n",
            " All: Speak, speak. \n",
            " First Citizen: Yo\n",
            "\n",
            "\n",
            "Tokenized and back mapped sequence:\n",
            "first citizen: before we proceed any further, hear me speak. \n",
            " all: speak, speak. \n",
            " first citizen: yo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWR70ie-1McB"
      },
      "source": [
        "# Almost done! Now we just need to form the datasets.\n",
        "# Let's make it so that we always want to predict one token ahead.\n",
        "# Thus input is all but last token in original positions, but target is all but first token in left shifted positions\n",
        "train_inputs = [item[0:-1] for item in train_seqs]\n",
        "train_targets = [item[1:] for item in train_seqs]\n",
        "\n",
        "val_inputs = [item[0:-1] for item in val_seqs]\n",
        "val_targets = [item[1:] for item in val_seqs]\n",
        "\n",
        "batch_size = 32\n",
        "train_dataset = Dataset.from_tensor_slices((train_inputs, train_targets)).shuffle(9999).batch(batch_size)\n",
        "validation_dataset = Dataset.from_tensor_slices((val_inputs, val_targets)).batch(batch_size)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGKj2MQ7_gLx"
      },
      "source": [
        "# Task 1.\n",
        "\n",
        "In this code we are going to train a simple model utilizing the self-attention blocks. The model is based on the Transformer model, but is slightly more simple.\n",
        "\n",
        "Finish the code for the self attention block \"SelfAttentionLayer\" in the following cell.\n",
        "\n",
        "You can call \"tf.matmul\" to perform matrix multiplication on batches of matrices to compute the $QK^\\top$ and the final output.\n",
        "\n",
        "Notice that we **need** to use masking as we are predicting the next token, otherwise this information will be leaked. Call the causal_softmax function inplace of the softmax used in the normal equations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiEoZr3d_agJ"
      },
      "source": [
        "@tf.function\n",
        "def causal_softmax(x,eps=1e-6):\n",
        "    # Assume x is of shape batch_size,sequence_length,sequence_length\n",
        "    # Generate a lower diagonal matrix of ones. First row has ones only at first element, second at first and second, and so on.\n",
        "    mask = tf.linalg.band_part(tf.ones((x.shape[1], x.shape[1])), -1, 0)\n",
        "    # In essence this could be just computed as exp(x)*mask/(sum(exp(x)*mask))\n",
        "    # However, here we utilize the numerically stabile version where we take the max out of the exponentiated matrix, which requries two maskings\n",
        "    # exp(x_j)/sum_i(exp(x_i)) = (exp(-x_max)*exp(x_j))/(exp(-x_max)*sum_i(exp(x_i))) = exp(x_j-x_max)/sum_i(x_i-x_max)\n",
        "    x = x*mask\n",
        "    maxx = tf.math.reduce_max(x,axis=2,keepdims=True)\n",
        "    x = x-maxx\n",
        "    x = tf.math.exp(x)*mask # We need to mask outside exp, since exp(0) = 1\n",
        "    x = x/(tf.math.reduce_sum(x,axis=2,keepdims=True)+eps)\n",
        "    return x\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "TASK IS TO COMPLETE THE NEXT:\n",
        "\"\"\"\n",
        "class SelfAttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dimension):\n",
        "        super(SelfAttentionLayer, self).__init__()\n",
        "        self.QMapping = layers.Dense(embedding_dimension)\n",
        "        self.KMapping = layers.Dense(embedding_dimension)\n",
        "        self.VMapping = layers.Dense(embedding_dimension)\n",
        "    \n",
        "    def call(self, input):\n",
        "        # Complete this call using the equations given.\n",
        "        # tf.matmul computes the matrix multiplication in batch mode if there is 3 dimensions so it is suitable.\n",
        "        # Also let's say we want to compute M1 * M2^T (M1 times M2 transposed)\n",
        "        # We can compute it using tf.matmul(M1,M2,transpose_b=True)\n",
        "        Q = self.QMapping(input)\n",
        "        K = self.KMapping(input)\n",
        "        V = self.VMapping(input)\n",
        "        # d_e is scaling as is shown above and in the paper.\n",
        "        d_e = tf.cast(tf.shape(K)[-1], tf.float32)\n",
        "        QK_t = tf.matmul(Q, K, transpose_b=True)\n",
        "        attention_weights = causal_softmax(QK_t)\n",
        "        output = tf.matmul(attention_weights, V)\n",
        "        return output\n",
        "\"\"\"\n",
        "END\n",
        "\"\"\"\n",
        "\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dim, dropout_rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attention = SelfAttentionLayer(embedding_dim)\n",
        "        self.fc1 = layers.Dense(embedding_dim, activation='relu')\n",
        "        self.fc2 = layers.Dense(embedding_dim, activation='relu')\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(dropout_rate)\n",
        "        self.dropout2 = layers.Dropout(dropout_rate)\n",
        "    def call(self, x, training):\n",
        "        attended = self.attention(x)\n",
        "        attended = self.dropout1(attended,training=training)\n",
        "        attended_normed = self.layernorm1(x+attended)\n",
        "        feed_forwarded = self.fc2(self.fc1(attended_normed))\n",
        "        feed_forwarded = self.dropout2(feed_forwarded,training=training)\n",
        "        output = self.layernorm2(feed_forwarded + attended_normed)\n",
        "        return output\n",
        "\n",
        "class MiniTransformer(tf.keras.Model):\n",
        "    def __init__(self,number_of_tokens,embedding_dim=256):\n",
        "        super(MiniTransformer, self).__init__()\n",
        "        # Embed the inputs to embedding_dim trainable vectors:\n",
        "        self.embedding = layers.Embedding(number_of_tokens, embedding_dim)\n",
        "        self.tblock1 = TransformerBlock(embedding_dim)\n",
        "        self.tblock2 = TransformerBlock(embedding_dim)\n",
        "        self.tblock3 = TransformerBlock(embedding_dim)\n",
        "        self.tblock4 = TransformerBlock(embedding_dim)\n",
        "        self.tblock5 = TransformerBlock(embedding_dim)\n",
        "        # Now map probabilities for each token\n",
        "        self.classifier = layers.Dense(number_of_tokens)\n",
        "    def call(self, x, training, as_logits = True):\n",
        "        x = self.embedding(x,training=training)\n",
        "        x = self.tblock1(x,training=training)\n",
        "        x = self.tblock2(x,training=training)\n",
        "        x = self.tblock3(x,training=training)\n",
        "        x = self.tblock4(x,training=training)\n",
        "        x = self.tblock5(x,training=training)\n",
        "        if as_logits:\n",
        "            return self.classifier(x)\n",
        "        else:\n",
        "            return tf.keras.activations.softmax(self.classifier(x), axis=-1)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUfgjI276RkO"
      },
      "source": [
        "# make the model:\n",
        "mini_transformer = MiniTransformer(vocab_size,embedding_dim=512)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKl5t3Mh9OF6"
      },
      "source": [
        "learning_rate = 0.0003\n",
        "mini_transformer.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
        "                         loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                         metrics=['accuracy'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFCH9nFj9uNg",
        "outputId": "dfde98b6-e02f-441e-b2ac-b4754484f0c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train and use the early stopping hook:\n",
        "epochs = 50\n",
        "history = mini_transformer.fit(train_dataset,\n",
        "                               epochs=epochs,\n",
        "                               validation_data=validation_dataset,\n",
        "                               callbacks=tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                                                          min_delta=0,\n",
        "                                                                          patience=10, \n",
        "                                                                          restore_best_weights=True))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "313/313 [==============================] - 47s 150ms/step - loss: 2.3003 - accuracy: 0.3065 - val_loss: 2.3118 - val_accuracy: 0.3019\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 47s 150ms/step - loss: 2.2904 - accuracy: 0.3091 - val_loss: 2.3090 - val_accuracy: 0.3038\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2941 - accuracy: 0.3077 - val_loss: 2.3133 - val_accuracy: 0.3020\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 46s 148ms/step - loss: 2.2935 - accuracy: 0.3077 - val_loss: 2.3238 - val_accuracy: 0.2987\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2904 - accuracy: 0.3088 - val_loss: 2.3108 - val_accuracy: 0.3047\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2818 - accuracy: 0.3114 - val_loss: 2.3098 - val_accuracy: 0.3019\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2791 - accuracy: 0.3116 - val_loss: 2.2990 - val_accuracy: 0.3066\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2704 - accuracy: 0.3144 - val_loss: 2.2965 - val_accuracy: 0.3076\n",
            "Epoch 9/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.3063 - accuracy: 0.3051 - val_loss: 2.3642 - val_accuracy: 0.2896\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.3233 - accuracy: 0.2991 - val_loss: 2.3198 - val_accuracy: 0.2992\n",
            "Epoch 11/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2907 - accuracy: 0.3082 - val_loss: 2.2963 - val_accuracy: 0.3072\n",
            "Epoch 12/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2779 - accuracy: 0.3115 - val_loss: 2.2846 - val_accuracy: 0.3096\n",
            "Epoch 13/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2945 - accuracy: 0.3078 - val_loss: 2.3170 - val_accuracy: 0.3012\n",
            "Epoch 14/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2906 - accuracy: 0.3082 - val_loss: 2.2940 - val_accuracy: 0.3059\n",
            "Epoch 15/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2707 - accuracy: 0.3140 - val_loss: 2.2935 - val_accuracy: 0.3077\n",
            "Epoch 16/50\n",
            "313/313 [==============================] - 46s 148ms/step - loss: 2.2556 - accuracy: 0.3189 - val_loss: 2.2866 - val_accuracy: 0.3110\n",
            "Epoch 17/50\n",
            "313/313 [==============================] - 46s 148ms/step - loss: 2.2530 - accuracy: 0.3196 - val_loss: 2.2751 - val_accuracy: 0.3124\n",
            "Epoch 18/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2603 - accuracy: 0.3176 - val_loss: 2.2808 - val_accuracy: 0.3115\n",
            "Epoch 19/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2523 - accuracy: 0.3200 - val_loss: 2.2782 - val_accuracy: 0.3135\n",
            "Epoch 20/50\n",
            "313/313 [==============================] - 46s 149ms/step - loss: 2.2404 - accuracy: 0.3236 - val_loss: 2.2697 - val_accuracy: 0.3169\n",
            "Epoch 21/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2450 - accuracy: 0.3226 - val_loss: 2.2882 - val_accuracy: 0.3093\n",
            "Epoch 22/50\n",
            "313/313 [==============================] - 46s 149ms/step - loss: 2.2436 - accuracy: 0.3227 - val_loss: 2.2676 - val_accuracy: 0.3178\n",
            "Epoch 23/50\n",
            "313/313 [==============================] - 46s 148ms/step - loss: 2.2254 - accuracy: 0.3286 - val_loss: 2.2655 - val_accuracy: 0.3200\n",
            "Epoch 24/50\n",
            "313/313 [==============================] - 46s 148ms/step - loss: 2.2460 - accuracy: 0.3228 - val_loss: 2.2579 - val_accuracy: 0.3200\n",
            "Epoch 25/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2162 - accuracy: 0.3314 - val_loss: 2.2522 - val_accuracy: 0.3245\n",
            "Epoch 26/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2560 - accuracy: 0.3201 - val_loss: 2.2582 - val_accuracy: 0.3230\n",
            "Epoch 27/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2317 - accuracy: 0.3276 - val_loss: 2.2940 - val_accuracy: 0.3066\n",
            "Epoch 28/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2376 - accuracy: 0.3253 - val_loss: 2.2472 - val_accuracy: 0.3253\n",
            "Epoch 29/50\n",
            "313/313 [==============================] - 46s 148ms/step - loss: 2.2147 - accuracy: 0.3317 - val_loss: 2.2404 - val_accuracy: 0.3283\n",
            "Epoch 30/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2053 - accuracy: 0.3347 - val_loss: 2.2330 - val_accuracy: 0.3286\n",
            "Epoch 31/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.1932 - accuracy: 0.3387 - val_loss: 2.2274 - val_accuracy: 0.3313\n",
            "Epoch 32/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2163 - accuracy: 0.3318 - val_loss: 2.3093 - val_accuracy: 0.3067\n",
            "Epoch 33/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2446 - accuracy: 0.3236 - val_loss: 2.2504 - val_accuracy: 0.3244\n",
            "Epoch 34/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.2120 - accuracy: 0.3327 - val_loss: 2.2510 - val_accuracy: 0.3225\n",
            "Epoch 35/50\n",
            "313/313 [==============================] - 46s 148ms/step - loss: 2.2013 - accuracy: 0.3367 - val_loss: 2.2309 - val_accuracy: 0.3322\n",
            "Epoch 36/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.1909 - accuracy: 0.3388 - val_loss: 2.2311 - val_accuracy: 0.3323\n",
            "Epoch 37/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.1885 - accuracy: 0.3400 - val_loss: 2.2325 - val_accuracy: 0.3298\n",
            "Epoch 38/50\n",
            "313/313 [==============================] - 47s 150ms/step - loss: 2.1893 - accuracy: 0.3393 - val_loss: 2.2359 - val_accuracy: 0.3287\n",
            "Epoch 39/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.1820 - accuracy: 0.3413 - val_loss: 2.2166 - val_accuracy: 0.3331\n",
            "Epoch 40/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.1660 - accuracy: 0.3465 - val_loss: 2.1995 - val_accuracy: 0.3413\n",
            "Epoch 41/50\n",
            "313/313 [==============================] - 46s 148ms/step - loss: 2.1718 - accuracy: 0.3453 - val_loss: 2.2192 - val_accuracy: 0.3341\n",
            "Epoch 42/50\n",
            "313/313 [==============================] - 46s 149ms/step - loss: 2.2090 - accuracy: 0.3347 - val_loss: 2.2359 - val_accuracy: 0.3285\n",
            "Epoch 43/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.1758 - accuracy: 0.3440 - val_loss: 2.2144 - val_accuracy: 0.3331\n",
            "Epoch 44/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.1617 - accuracy: 0.3478 - val_loss: 2.2038 - val_accuracy: 0.3385\n",
            "Epoch 45/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.1604 - accuracy: 0.3486 - val_loss: 2.2124 - val_accuracy: 0.3357\n",
            "Epoch 46/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.1614 - accuracy: 0.3481 - val_loss: 2.2021 - val_accuracy: 0.3362\n",
            "Epoch 47/50\n",
            "313/313 [==============================] - 46s 148ms/step - loss: 2.1582 - accuracy: 0.3489 - val_loss: 2.1956 - val_accuracy: 0.3393\n",
            "Epoch 48/50\n",
            "313/313 [==============================] - 46s 148ms/step - loss: 2.1606 - accuracy: 0.3485 - val_loss: 2.2060 - val_accuracy: 0.3385\n",
            "Epoch 49/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.3956 - accuracy: 0.2937 - val_loss: 2.7596 - val_accuracy: 0.2183\n",
            "Epoch 50/50\n",
            "313/313 [==============================] - 47s 149ms/step - loss: 2.6894 - accuracy: 0.2323 - val_loss: 2.6737 - val_accuracy: 0.2289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_WbVyBG9v60",
        "outputId": "a073fb40-3617-4d0d-ecba-816c7d0f139b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and Validation Accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be23_Ujt91SE"
      },
      "source": [
        "# Generate text using the model. Here are some utility functions which you can use.\n",
        "def complete_string(model,init_string,sequence_length,tokenizer=tokenizer):\n",
        "    prediction_index = len(init_string)-1\n",
        "    data = [init_string]\n",
        "    sequence = tokenizer.texts_to_sequences(data)\n",
        "    # We want to generate the string by predicting one step ahead, and then\n",
        "    # appending the t+1 predicted token into the sequence:\n",
        "    while prediction_index < sequence_length:\n",
        "        probabilities = model(tf.convert_to_tensor(sequence, dtype=tf.float32),training=False,as_logits=False)\n",
        "        # probabilities is 1 x sequence_length x number_of_tokens.\n",
        "        # Get the predictions on the next token by:\n",
        "        p_next = probabilities[0,prediction_index,:].numpy()\n",
        "\n",
        "        # There might be some floating point errors, which numpy does not like.\n",
        "        # Thus do this:\n",
        "        p_next = p_next.astype('float64')\n",
        "        p_next = p_next/np.sum(p_next)\n",
        "\n",
        "        # Often it is better to sample the next token rather than to use the one with maximum probability:\n",
        "        pred_next = np.argmax(np.random.multinomial(1,p_next))\n",
        "        sequence[0].append(pred_next)\n",
        "        prediction_index = len(sequence[0])-1\n",
        "    \n",
        "    return sequences_to_text(sequence,tokenizer)[0]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUA6IV78He6T"
      },
      "source": [
        "# Task 2\n",
        "Generate different strings using the model by changing the \"string_to_complete\" to something else.\n",
        "What can you say about the quality of the generated strings? What happens if you feed some \"out-of-distribution\" initial string? For example there is probably nothing about AI in Shakespeare..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcRwDfBtGLKv",
        "outputId": "ae05bb8c-3cd5-427c-d808-3e5e57b3e311",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Modify this string and run this cell to make the model generate ending to the initial string.\n",
        "string_to_complete = \"Artificial Intelligence is \"\n",
        "completed_string = complete_string(mini_transformer,init_string=string_to_complete,sequence_length=50)\n",
        "print(completed_string)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "artificial intelligence is maso: wa merelyansouimel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZh9aeERbyFQ",
        "outputId": "c43fd467-7ba8-475f-e3d9-65e6deb38beb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "string_to_complete = \"The meaning of life is to \"\n",
        "completed_string = complete_string(mini_transformer,init_string=string_to_complete,sequence_length=50)\n",
        "print(completed_string)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the meaning of life is to gro wilothe o bere fe yor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFxj7QA6cS4m",
        "outputId": "3bd8ce19-8923-49a3-ce71-c9625296c489",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "string_to_complete = \"The next president of the United States is \"\n",
        "completed_string = complete_string(mini_transformer,init_string=string_to_complete,sequence_length=55)\n",
        "print(completed_string)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the next president of the united states is wi ac s to ie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h2Bbfyqca8F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}